{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Inferer_Video' from 'yolov6.core.inferer' (/home/alberto/Desktop/repos/public_repos/YOLOv6/yolov6/core/inferer.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-be6131ddd404>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0myolov6\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLOGGER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0myolov6\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInferer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInferer_Video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Inferer_Video' from 'yolov6.core.inferer' (/home/alberto/Desktop/repos/public_repos/YOLOv6/yolov6/core/inferer.py)"
     ]
    }
   ],
   "source": [
    "# OpenVINO imports\n",
    "import collections\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "from openvino.runtime import Core\n",
    "\n",
    "\n",
    "#import utils.notebook_utils as utils\n",
    "#YOLOv6 imports\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "\n",
    "ROOT = os.getcwd()\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "from yolov6.utils.events import LOGGER\n",
    "from yolov6.core.inferer import Inferer, Inferer_Video\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_model_path = \"/home/alberto/Desktop/repos/public_repos/YOLOv6/yolov6s_openvino/yolov6s.xml\"\n",
    "\n",
    "\n",
    "# initialize inference engine\n",
    "ie_core = Core()\n",
    "# read the network and corresponding weights from file\n",
    "model = ie_core.read_model(model=converted_model_path)\n",
    "# compile the model for the CPU (you can choose manually CPU, GPU, MYRIAD etc.)\n",
    "# or let the engine choose the best available device (AUTO)\n",
    "compiled_model = ie_core.compile_model(model=model, device_name=\"CPU\")\n",
    "\n",
    "# get input and output nodes\n",
    "input_layer = compiled_model.input(0)\n",
    "output_layer = compiled_model.output(0)\n",
    "\n",
    "# get input size\n",
    "height, width = list(input_layer.shape)[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Shape: {1, 3, 640, 640}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_layer.any_name, output_layer.any_name\n",
    "input_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/\n",
    "classes = [\n",
    "    \"background\", \"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\",\n",
    "    \"truck\", \"boat\", \"traffic light\", \"fire hydrant\", \"street sign\", \"stop sign\",\n",
    "    \"parking meter\", \"bench\", \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\",\n",
    "    \"bear\", \"zebra\", \"giraffe\", \"hat\", \"backpack\", \"umbrella\", \"shoe\", \"eye glasses\",\n",
    "    \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\",\n",
    "    \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\",\n",
    "    \"plate\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\",\n",
    "    \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\",\n",
    "    \"couch\", \"potted plant\", \"bed\", \"mirror\", \"dining table\", \"window\", \"desk\", \"toilet\",\n",
    "    \"door\", \"tv\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\",\n",
    "    \"toaster\", \"sink\", \"refrigerator\", \"blender\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "    \"teddy bear\", \"hair drier\", \"toothbrush\", \"hair brush\"\n",
    "]\n",
    "\n",
    "# colors for above classes (Rainbow Color Map)\n",
    "colors = cv2.applyColorMap(\n",
    "    src=np.arange(0, 255, 255 / len(classes), dtype=np.float32).astype(np.uint8),\n",
    "    colormap=cv2.COLORMAP_RAINBOW,\n",
    ").squeeze()\n",
    "\n",
    "\n",
    "def process_results(frame, results, thresh=0.6):\n",
    "    # size of the original frame\n",
    "    h, w = frame.shape[:2]\n",
    "    # results is a tensor [1, 1, 100, 7]\n",
    "    results = results.squeeze()\n",
    "    boxes = []\n",
    "    labels = []\n",
    "    scores = []\n",
    "    for _, label, score, xmin, ymin, xmax, ymax in results:\n",
    "        # create a box with pixels coordinates from the box with normalized coordinates [0,1]\n",
    "        boxes.append(\n",
    "            tuple(map(int, (xmin * w, ymin * h, (xmax - xmin) * w, (ymax - ymin) * h)))\n",
    "        )\n",
    "        labels.append(int(label))\n",
    "        scores.append(float(score))\n",
    "\n",
    "    # apply non-maximum suppression to get rid of many overlapping entities\n",
    "    # see https://paperswithcode.com/method/non-maximum-suppression\n",
    "    # this algorithm returns indices of objects to keep\n",
    "    indices = cv2.dnn.NMSBoxes(\n",
    "        bboxes=boxes, scores=scores, score_threshold=thresh, nms_threshold=0.6\n",
    "    )\n",
    "\n",
    "    # if there are no boxes\n",
    "    if len(indices) == 0:\n",
    "        return []\n",
    "\n",
    "    # filter detected objects\n",
    "    return [(labels[idx], scores[idx], boxes[idx]) for idx in indices.flatten()]\n",
    "\n",
    "\n",
    "def draw_boxes(frame, boxes):\n",
    "    for label, score, box in boxes:\n",
    "        # choose color for the label\n",
    "        color = tuple(map(int, colors[label]))\n",
    "        # draw box\n",
    "        x2 = box[0] + box[2]\n",
    "        y2 = box[1] + box[3]\n",
    "        cv2.rectangle(img=frame, pt1=box[:2], pt2=(x2, y2), color=color, thickness=3)\n",
    "\n",
    "        # draw label name inside the box\n",
    "        cv2.putText(\n",
    "            img=frame,\n",
    "            text=f\"{classes[label]} {score:.2f}\",\n",
    "            org=(box[0] + 10, box[1] + 30),\n",
    "            fontFace=cv2.FONT_HERSHEY_COMPLEX,\n",
    "            fontScale=frame.shape[1] / 1000,\n",
    "            color=color,\n",
    "            thickness=1,\n",
    "            lineType=cv2.LINE_AA,\n",
    "        )\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding:utf-8 -*-\n",
    "# The code is based on\n",
    "# https://github.com/ultralytics/yolov5/blob/master/utils/general.py\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "\n",
    "# Settings\n",
    "torch.set_printoptions(linewidth=320, precision=5, profile='long')\n",
    "np.set_printoptions(linewidth=320, formatter={'float_kind': '{:11.5g}'.format})  # format short g, %precision=5\n",
    "cv2.setNumThreads(0)  # prevent OpenCV from multithreading (incompatible with PyTorch DataLoader)\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = str(min(os.cpu_count(), 8))  # NumExpr max threads\n",
    "\n",
    "\n",
    "def xywh2xyxy(x):\n",
    "    # Convert boxes with shape [n, 4] from [x, y, w, h] to [x1, y1, x2, y2] where x1y1 is top-left, x2y2=bottom-right\n",
    "    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)\n",
    "    y[:, 0] = x[:, 0] - x[:, 2] / 2  # top left x\n",
    "    y[:, 1] = x[:, 1] - x[:, 3] / 2  # top left y\n",
    "    y[:, 2] = x[:, 0] + x[:, 2] / 2  # bottom right x\n",
    "    y[:, 3] = x[:, 1] + x[:, 3] / 2  # bottom right y\n",
    "    return y\n",
    "\n",
    "\n",
    "def non_max_suppression(prediction, conf_thres=0.25, iou_thres=0.45, classes=None, agnostic=False, multi_label=False, max_det=300):\n",
    "    \"\"\"Runs Non-Maximum Suppression (NMS) on inference results.\n",
    "    This code is borrowed from: https://github.com/ultralytics/yolov5/blob/47233e1698b89fc437a4fb9463c815e9171be955/utils/general.py#L775\n",
    "    Args:\n",
    "        prediction: (tensor), with shape [N, 5 + num_classes], N is the number of bboxes.\n",
    "        conf_thres: (float) confidence threshold.\n",
    "        iou_thres: (float) iou threshold.\n",
    "        classes: (None or list[int]), if a list is provided, nms only keep the classes you provide.\n",
    "        agnostic: (bool), when it is set to True, we do class-independent nms, otherwise, different class would do nms respectively.\n",
    "        multi_label: (bool), when it is set to True, one box can have multi labels, otherwise, one box only huave one label.\n",
    "        max_det:(int), max number of output bboxes.\n",
    "\n",
    "    Returns:\n",
    "         list of detections, echo item is one tensor with shape (num_boxes, 6), 6 is for [xyxy, conf, cls].\n",
    "    \"\"\"\n",
    "\n",
    "    num_classes = prediction.shape[2] - 5  # number of classes\n",
    "    pred_candidates = prediction[..., 4] > conf_thres  # candidates\n",
    "\n",
    "    # Check the parameters.\n",
    "    assert 0 <= conf_thres <= 1, f'conf_thresh must be in 0.0 to 1.0, however {conf_thres} is provided.'\n",
    "    assert 0 <= iou_thres <= 1, f'iou_thres must be in 0.0 to 1.0, however {iou_thres} is provided.'\n",
    "\n",
    "    # Function settings.\n",
    "    max_wh = 4096  # maximum box width and height\n",
    "    max_nms = 30000  # maximum number of boxes put into torchvision.ops.nms()\n",
    "    time_limit = 10.0  # quit the function when nms cost time exceed the limit time.\n",
    "    multi_label &= num_classes > 1  # multiple labels per box\n",
    "\n",
    "    tik = time.time()\n",
    "    output = [torch.zeros((0, 6), device=prediction.device)] * prediction.shape[0]\n",
    "    for img_idx, x in enumerate(prediction):  # image index, image inference\n",
    "        x = x[pred_candidates[img_idx]]  # confidence\n",
    "\n",
    "        # If no box remains, skip the next process.\n",
    "        if not x.shape[0]:\n",
    "            continue\n",
    "\n",
    "        # confidence multiply the objectness\n",
    "        x[:, 5:] *= x[:, 4:5]  # conf = obj_conf * cls_conf\n",
    "\n",
    "        # (center x, center y, width, height) to (x1, y1, x2, y2)\n",
    "        box = xywh2xyxy(x[:, :4])\n",
    "\n",
    "        # Detections matrix's shape is  (n,6), each row represents (xyxy, conf, cls)\n",
    "        if multi_label:\n",
    "            box_idx, class_idx = (x[:, 5:] > conf_thres).nonzero(as_tuple=False).T\n",
    "            x = torch.cat((box[box_idx], x[box_idx, class_idx + 5, None], class_idx[:, None].float()), 1)\n",
    "        else:  # Only keep the class with highest scores.\n",
    "            conf, class_idx = x[:, 5:].max(1, keepdim=True)\n",
    "            x = torch.cat((box, conf, class_idx.float()), 1)[conf.view(-1) > conf_thres]\n",
    "\n",
    "        # Filter by class, only keep boxes whose category is in classes.\n",
    "        if classes is not None:\n",
    "            x = x[(x[:, 5:6] == torch.tensor(classes, device=x.device)).any(1)]\n",
    "\n",
    "        # Check shape\n",
    "        num_box = x.shape[0]  # number of boxes\n",
    "        if not num_box:  # no boxes kept.\n",
    "            continue\n",
    "        elif num_box > max_nms:  # excess max boxes' number.\n",
    "            x = x[x[:, 4].argsort(descending=True)[:max_nms]]  # sort by confidence\n",
    "\n",
    "        # Batched NMS\n",
    "        class_offset = x[:, 5:6] * (0 if agnostic else max_wh)  # classes\n",
    "        boxes, scores = x[:, :4] + class_offset, x[:, 4]  # boxes (offset by class), scores\n",
    "        keep_box_idx = torchvision.ops.nms(boxes, scores, iou_thres)  # NMS\n",
    "        if keep_box_idx.shape[0] > max_det:  # limit detections\n",
    "            keep_box_idx = keep_box_idx[:max_det]\n",
    "\n",
    "        output[img_idx] = x[keep_box_idx]\n",
    "        if (time.time() - tik) > time_limit:\n",
    "            print(f'WARNING: NMS cost time exceed the limited {time_limit}s.')\n",
    "            break  # time limit exceeded\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letterbox(im, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleup=True, stride=32):\n",
    "    # Resize and pad image while meeting stride-multiple constraints\n",
    "    shape = im.shape[:2]  # current shape [height, width]\n",
    "    if isinstance(new_shape, int):\n",
    "        new_shape = (new_shape, new_shape)\n",
    "\n",
    "    # Scale ratio (new / old)\n",
    "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "    if not scaleup:  # only scale down, do not scale up (for better val mAP)\n",
    "        r = min(r, 1.0)\n",
    "\n",
    "    # Compute padding\n",
    "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
    "\n",
    "    if auto:  # minimum rectangle\n",
    "        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding\n",
    "\n",
    "    dw /= 2  # divide padding into 2 sides\n",
    "    dh /= 2\n",
    "\n",
    "    if shape[::-1] != new_unpad:  # resize\n",
    "        im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "    im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
    "    return im, r, (dw, dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale(ori_shape, boxes, target_shape):\n",
    "        '''Rescale the output to the original image shape'''\n",
    "        ratio = min(ori_shape[0] / target_shape[0], ori_shape[1] / target_shape[1])\n",
    "        padding = (ori_shape[1] - target_shape[1] * ratio) / 2, (ori_shape[0] - target_shape[0] * ratio) / 2\n",
    "\n",
    "        boxes[:, [0, 2]] -= padding[0]\n",
    "        boxes[:, [1, 3]] -= padding[1]\n",
    "        boxes[:, :4] /= ratio\n",
    "\n",
    "        boxes[:, 0].clamp_(0, target_shape[1])  # x1\n",
    "        boxes[:, 1].clamp_(0, target_shape[0])  # y1\n",
    "        boxes[:, 2].clamp_(0, target_shape[1])  # x2\n",
    "        boxes[:, 3].clamp_(0, target_shape[0])  # y2\n",
    "\n",
    "        return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precess_image(img_src, img_size, stride, half):\n",
    "        '''Process image before image inference.'''\n",
    "\n",
    "        image = letterbox(img_src, img_size, stride=stride)[0]\n",
    "\n",
    "        # Convert\n",
    "        image = image.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
    "        #image = torch.from_numpy(np.ascontiguousarray(image))\n",
    "        #image = image.half() if half else image.float()  # uint8 to fp16/32\n",
    "        print(type(image))\n",
    "        image = np.ascontiguousarray(image).astype(np.float64)\n",
    "        print(type(image))\n",
    "        image /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "\n",
    "        return image, img_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main processing function to run object detection\n",
    "def run_object_detection(source=0, flip=False, use_popup=False, skip_first_frames=0):\n",
    "    player = None\n",
    "    try:\n",
    "        # create video player to play with target fps\n",
    "        #player = utils.VideoPlayer(\n",
    "        #    source=source, flip=flip, fps=30, skip_first_frames=skip_first_frames\n",
    "        #)\n",
    "        # start capturing\n",
    "        #player.start()\n",
    "        \n",
    "        cap = cv2.VideoCapture(source)\n",
    "        \n",
    "\n",
    "        processing_times = collections.deque()\n",
    "        while True:\n",
    "            # grab the frame\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            #print(frame.shape)\n",
    "            \n",
    "            if frame is None:\n",
    "                print(\"Source ended\")\n",
    "                break\n",
    "            \n",
    "            \n",
    "            frame = cv2.resize(frame, (640, 640))\n",
    "            input_img, img_src = precess_image(frame, 640, 32, True)\n",
    "            #input_img = input_img.to('cpu')\n",
    "            \n",
    "        \n",
    "            if len(input_img.shape) == 3:\n",
    "                    input_img = input_img[None]\n",
    "            # create batch of images (size = 1)\n",
    "            input_img = input_img[np.newaxis, ...]\n",
    "            \n",
    "            #print(input_img.shape)\n",
    "\n",
    "            # measure processing time\n",
    "\n",
    "            start_time = time.time()\n",
    "            # get results\n",
    "            #print(\"Into the model it goes!\")\n",
    "            #results = compiled_model([input_img])[output_layer]\n",
    "            print(input_img.shape)\n",
    "            \n",
    "            input_img = input_img.tolist()\n",
    "            start_time = time.time()\n",
    "            pred_results = compiled_model(input_img)\n",
    "            #print(\"It came out the other side!\")\n",
    "            print(\"FPS: \" + str(1.0 / (time.time() - start_time)))\n",
    "            pred_results = pred_results[output_layer]\n",
    "            continue \n",
    "            \n",
    "            det = non_max_suppression(pred_results)\n",
    "            print(det)\n",
    "            continue \n",
    "            \n",
    "            \n",
    "            if len(det):\n",
    "                det[:, :4] = rescale(img.shape[2:], det[:, :4], img_src.shape).round()\n",
    "\n",
    "                for *xyxy, conf, cls in reversed(det):\n",
    "                    if save_txt:  # Write to file\n",
    "                        xywh = (self.box_convert(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n",
    "                        line = (cls, *xywh, conf)\n",
    "                        with open(txt_path + '.txt', 'a') as f:\n",
    "                            f.write(('%g ' * len(line)).rstrip() % line + '\\n')\n",
    "\n",
    "                    if save_img:\n",
    "                        class_num = int(cls)  # integer class\n",
    "                        label = None if hide_labels else (self.class_names[class_num] if hide_conf else f'{self.class_names[class_num]} {conf:.2f}')\n",
    "\n",
    "                        self.plot_box_and_label(img_ori, max(round(sum(img_ori.shape) / 2 * 0.003), 2), xyxy, label, color=self.generate_colors(class_num, True))\n",
    "\n",
    "                img_src = np.asarray(img_ori)\n",
    "\n",
    "                # Save results (image with detections)\n",
    "                if save_img:\n",
    "                    cv2.imwrite(save_path, img_src)\n",
    "            return\n",
    "            \n",
    "            \n",
    "    # ctrl-c\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")\n",
    "    # any different error\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        if player is not None:\n",
    "            # stop capturing\n",
    "            player.stop()\n",
    "        if use_popup:\n",
    "            cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 9.994862336350161\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 8.558738606010273\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 10.6758705650878\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 9.810801391283194\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 8.910836482917885\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 9.754444881148123\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 9.36048883473262\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 9.742549603497215\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 8.928192225330047\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 8.692659856459231\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 9.772217135321652\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 8.939609788951834\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 10.047151597031586\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 9.814681174681175\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 8.989714231825225\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 10.6514972979562\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 10.65330993195482\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 10.402023709141412\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 10.658995321462061\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 10.142487510216716\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 10.67239348099897\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 10.640688423445365\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 10.635507951963648\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 9.257396110144876\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 9.975156668053987\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 10.616018547578792\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 8.78320213931067\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 9.182006847695689\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 10.467598716227345\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 10.330874366066745\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 10.50035549413685\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 10.633917049289222\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 10.678398305429956\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 9.473857301614549\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 10.52789791139034\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 9.791791273004023\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 8.995671924127844\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 9.924739299261022\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 8.927451093075874\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 9.000864827281331\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 8.944127776178442\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 9.422861250898634\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 9.90145064387814\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 8.505852673248052\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 10.659022409262564\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 10.683920006317168\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 10.274515952026338\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 10.646927870641841\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 9.800371050577839\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 10.66165058045099\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 10.378318458161878\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 9.187155561396592\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 8.229531162626431\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 9.906010722467585\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 9.110882305663804\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 8.683607514481983\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 9.416768446009053\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 9.003241275388202\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 9.376853325702431\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 8.350446459679265\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 8.724446857325903\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 9.744201876679963\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 8.554427013224341\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 9.150117367819401\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 9.825786486188907\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 9.218635503460584\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 9.211266182784483\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 9.864934979408382\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 8.493089993095055\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 9.473172582641455\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 8.591628173745608\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 9.519722372903669\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 9.826292916632502\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 10.681525661562283\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 10.685417016961933\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 10.609010175716385\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 10.689774343342695\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 10.708442052481349\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 10.659645466675139\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 10.641093360327378\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 10.33408151851204\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 10.572267579469004\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 10.640175547635053\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 10.680356087921938\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "FPS: 10.659726740403384\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1, 3, 640, 640)\n",
      "Interrupted\n"
     ]
    }
   ],
   "source": [
    "run_object_detection(source=1, flip=True, use_popup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
